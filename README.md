# NaiveBayesClassifier
I have built and used a NaiveBayesClassifier to predict the outcome of basketball games using previous data

Architecture: I have implemented my Naive Bayes Classifier Model using the Numpy and Pandas libraries in Python. My classifier consists of two files: the NaiveBayesClassifier.sh (which is the shell file that helps execute my code) and the NaiveBayesClassifier.py file which contains the model. The NumPy library is used primarily for mathematical calculations while the Pandas library is used to help handle data manipulation related issues. While building my classifier, I had kept in mind to organize the different aspects of the code to make it easier to follow and understand. The class has attributes for storing prior probabilities (oldProb), likelihoods of categorical features (likelihood), and statistical parameters for numerical features (stats). 
Preprocessing: The first key step to getting started was preprocessing the data which was given in the csv files. The main reason to preprocess the data which was given to me was to make it structured and easy to read for the classifier. For example, the data in the csv files was very raw and very informative as there were many different attributes and not all of them were previously described using numerical values (like wins and losses). In order for us to run the classifier, we need everything to be numerical so a key part of preprocessing the data was to use a binary system to define wins and losses. The binary representation helps us make the mathematical calculations easier when we are trying to train the model. In order to address any anomalies or missing variables that could otherwise distort the accuracy of the model, preprocessing also includes cleaning the data.
	Model Building: Next came the process of training my model which I did using the fit function. The goal of this portion of the code was to use the training data to help give my model more context so that it would be able to recognize patterns. With these patterns it would be able to predict the future games with higher accuracy. Given the training data which has already been preprocessed, the fit function starts by using numpy's np.unique() method to pick out unique class labels from the dataset's label column. The dataset is divided into discrete classes in this step, which the Naive Bayes model will use to make predictions. For each of these classes, the model next calculates the old probabilities. By dividing the number of occurrences of each class by the total number of instances, this represents the probability that each class will appear in the dataset. This lays the groundwork for Bayes' Theorem, which modifies these priors in accordance with the features' likelihood. Next in this algorithm, we need to estimate the likelihoods of both our categorical features and our numerical features. For the categorical features we use conditional probability to help estimate whereas for the numerical features we use mean and standard deviation. We also assume that the data in the Naive Bayes Model follows a normal distribution pattern which helps us with a formula that we can use to calculate the estimates. This whole function essentially trains the model.
